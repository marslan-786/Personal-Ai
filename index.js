require('dotenv').config();
const express = require('express');
const mongoose = require('mongoose');
const axios = require('axios');
const cors = require('cors');
const path = require('path');

const app = express();
const PORT = process.env.PORT || 8080;

// Middleware
app.use(cors());
app.use(express.json());
app.use(express.static('public'));

// MongoDB Connection
mongoose.connect(process.env.MONGO_URI)
  .then(() => console.log('ðŸƒ Memory Database: Connected & Active'))
  .catch(err => console.error('âŒ Database Connection Error:', err));

// Chat Schema (ÛŒØ§Ø¯Ø¯Ø§Ø´Øª Ú©Ø§ ÚˆÚ¾Ø§Ù†Ú†Û)
const chatSchema = new mongoose.Schema({
    sessionId: { type: String, required: true, unique: true },
    messages: [
        {
            role: String, // 'user' or 'assistant'
            content: String,
            timestamp: { type: Date, default: Date.now }
        }
    ]
});
const Chat = mongoose.model('Chat', chatSchema);

// --- AI CHAT LOGIC WITH MEMORY ---

app.post('/api/chat', async (req, res) => {
    const { message, sessionId } = req.body;

    try {
        // 1. ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø³Û’ Ø§Ø³ Ø³ÛŒØ´Ù† Ú©ÛŒ Ù¾Ø±Ø§Ù†ÛŒ ÛŒØ§Ø¯Ø¯Ø§Ø´Øª ØªÙ„Ø§Ø´ Ú©Ø±ÛŒÚº
        let userChat = await Chat.findOne({ sessionId });
        if (!userChat) {
            userChat = new Chat({ sessionId, messages: [] });
        }

        // 2. ÛŒÙˆØ²Ø± Ú©Ø§ Ù†ÛŒØ§ Ù…ÛŒØ³Ø¬ ÛØ³Ù¹Ø±ÛŒ Ù…ÛŒÚº ÚˆØ§Ù„ÛŒÚº
        userChat.messages.push({ role: 'user', content: message });

        // 3. AI Ú©Ùˆ Ø¨Ú¾ÛŒØ¬Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ù¾ÙˆØ±ÛŒ ÛØ³Ù¹Ø±ÛŒ ØªÛŒØ§Ø± Ú©Ø±ÛŒÚº
        // Ú†ÙˆÙ†Ú©Û Ø¢Ù¾ Ú©Û’ Ù¾Ø§Ø³ 32GB RAM ÛÛ’ØŒ ÛÙ… Ù„Ù…Ø¨ÛŒ ÛØ³Ù¹Ø±ÛŒ Ø¨Ú¾ÛŒØ¬ Ø³Ú©ØªÛ’ ÛÛŒÚº
        const historyForAI = userChat.messages.map(msg => ({
            role: msg.role,
            content: msg.content
        }));

        // 4. Ollama (Llama 3.1) Ú©Ùˆ Ú©Ø§Ù„ Ú©Ø±ÛŒÚº
        const aiResponse = await axios.post(`${process.env.OLLAMA_URL}/api/chat`, {
            model: "llama3.1:8b",
            messages: historyForAI,
            stream: false,
            options: {
                num_ctx: 32768 // 32GB RAM Ú©ÛŒ ÙˆØ¬Û Ø³Û’ ÛÙ… Context Window Ú©Ùˆ Ø¨Ú‘Ø§ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚº
            }
        });

        const botReply = aiResponse.data.message.content;

        // 5. AI Ú©Ø§ Ø¬ÙˆØ§Ø¨ Ø¨Ú¾ÛŒ ÛŒØ§Ø¯Ø¯Ø§Ø´Øª (DB) Ù…ÛŒÚº Ù…Ø­ÙÙˆØ¸ Ú©Ø±ÛŒÚº
        userChat.messages.push({ role: 'assistant', content: botReply });
        await userChat.save();

        // 6. Ø¬ÙˆØ§Ø¨ ÙˆØ§Ù¾Ø³ Ø¨Ú¾ÛŒØ¬ÛŒÚº
        res.json({ reply: botReply });

    } catch (error) {
        console.error('âŒ Chat Error:', error.message);
        res.status(500).json({ reply: "ÛŒØ§Ø±ØŒ Ø³Ø±ÙˆØ± Ù…ÛŒÚº Ú©Ú†Ú¾ Ù…Ø³Ø¦Ù„Û Ø¢ Ø±ÛØ§ ÛÛ’ØŒ Ù„ÛŒÚ©Ù† Ù…ÛŒÚº ÛŒØ§Ø¯Ø¯Ø§Ø´Øª Ø¨Ú†Ø§Ù†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”" });
    }
});

// ÛÙˆÙ… Ù¾ÛŒØ¬ Ø±ÙˆÙ¹
app.get('*', (req, res) => {
    res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

app.listen(PORT, '0.0.0.0', () => {
    console.log(`ðŸš€ AI Engine Started on Port ${PORT}`);
});
